{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os.chdir(\"D:\\machine_learning\\Image_recognition\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "#device=torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 3, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 5923\n",
      "1 = 6742\n",
      "2 = 5958\n",
      "3 = 6131\n",
      "4 = 5842\n",
      "5 = 5421\n",
      "6 = 5918\n",
      "7 = 6265\n",
      "8 = 5851\n",
      "9 = 5949\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i,\"=\",len(np.where(df['label']==i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.453933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.889270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042472</td>\n",
       "      <td>3.956189</td>\n",
       "      <td>2.839845</td>\n",
       "      <td>1.686770</td>\n",
       "      <td>1.678283</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
       "count  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
       "mean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
       "count  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.200433      0.088867   \n",
       "std        0.0      0.0      0.0  ...      6.042472      3.956189   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "              28x21         28x22         28x23       28x24    28x25    28x26  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \n",
       "mean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \n",
       "std        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "max      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n",
       "\n",
       "         28x27    28x28  \n",
       "count  60000.0  60000.0  \n",
       "mean       0.0      0.0  \n",
       "std        0.0      0.0  \n",
       "min        0.0      0.0  \n",
       "25%        0.0      0.0  \n",
       "50%        0.0      0.0  \n",
       "75%        0.0      0.0  \n",
       "max        0.0      0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3ST75--KRNtJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1x1',\n",
       " '1x2',\n",
       " '1x3',\n",
       " '1x4',\n",
       " '1x5',\n",
       " '1x6',\n",
       " '1x7',\n",
       " '1x8',\n",
       " '1x9',\n",
       " '1x10',\n",
       " '1x11',\n",
       " '1x12',\n",
       " '1x13',\n",
       " '1x14',\n",
       " '1x15',\n",
       " '1x16',\n",
       " '1x17',\n",
       " '1x18',\n",
       " '1x19',\n",
       " '1x20',\n",
       " '1x21',\n",
       " '1x22',\n",
       " '1x23',\n",
       " '1x24',\n",
       " '1x25',\n",
       " '1x26',\n",
       " '1x27',\n",
       " '1x28',\n",
       " '2x1',\n",
       " '2x2',\n",
       " '2x3',\n",
       " '2x4',\n",
       " '2x5',\n",
       " '2x6',\n",
       " '2x7',\n",
       " '2x8',\n",
       " '2x9',\n",
       " '2x10',\n",
       " '2x11',\n",
       " '2x12',\n",
       " '2x13',\n",
       " '2x14',\n",
       " '2x15',\n",
       " '2x16',\n",
       " '2x17',\n",
       " '2x18',\n",
       " '2x19',\n",
       " '2x20',\n",
       " '2x21',\n",
       " '2x22',\n",
       " '2x23',\n",
       " '2x24',\n",
       " '2x25',\n",
       " '2x26',\n",
       " '2x27',\n",
       " '2x28',\n",
       " '3x1',\n",
       " '3x2',\n",
       " '3x3',\n",
       " '3x4',\n",
       " '3x5',\n",
       " '3x6',\n",
       " '3x7',\n",
       " '3x8',\n",
       " '3x9',\n",
       " '3x10',\n",
       " '3x11',\n",
       " '3x12',\n",
       " '3x13',\n",
       " '3x14',\n",
       " '3x15',\n",
       " '3x16',\n",
       " '3x17',\n",
       " '3x18',\n",
       " '3x19',\n",
       " '3x20',\n",
       " '3x21',\n",
       " '3x22',\n",
       " '3x23',\n",
       " '3x24',\n",
       " '3x25',\n",
       " '3x26',\n",
       " '3x27',\n",
       " '3x28',\n",
       " '4x1',\n",
       " '4x2',\n",
       " '4x3',\n",
       " '4x4',\n",
       " '4x5',\n",
       " '4x6',\n",
       " '4x7',\n",
       " '4x8',\n",
       " '4x9',\n",
       " '4x10',\n",
       " '4x11',\n",
       " '4x12',\n",
       " '4x13',\n",
       " '4x14',\n",
       " '4x15',\n",
       " '4x16',\n",
       " '4x17',\n",
       " '4x18',\n",
       " '4x19',\n",
       " '4x20',\n",
       " '4x21',\n",
       " '4x22',\n",
       " '4x23',\n",
       " '4x24',\n",
       " '4x25',\n",
       " '4x26',\n",
       " '4x27',\n",
       " '4x28',\n",
       " '5x1',\n",
       " '5x2',\n",
       " '5x3',\n",
       " '5x4',\n",
       " '5x5',\n",
       " '5x6',\n",
       " '5x7',\n",
       " '5x8',\n",
       " '5x9',\n",
       " '5x10',\n",
       " '5x11',\n",
       " '5x12',\n",
       " '5x13',\n",
       " '5x14',\n",
       " '5x15',\n",
       " '5x16',\n",
       " '5x17',\n",
       " '5x18',\n",
       " '5x19',\n",
       " '5x20',\n",
       " '5x21',\n",
       " '5x22',\n",
       " '5x23',\n",
       " '5x24',\n",
       " '5x25',\n",
       " '5x26',\n",
       " '5x27',\n",
       " '5x28',\n",
       " '6x1',\n",
       " '6x2',\n",
       " '6x3',\n",
       " '6x4',\n",
       " '6x5',\n",
       " '6x6',\n",
       " '6x7',\n",
       " '6x8',\n",
       " '6x9',\n",
       " '6x10',\n",
       " '6x11',\n",
       " '6x12',\n",
       " '6x13',\n",
       " '6x14',\n",
       " '6x15',\n",
       " '6x16',\n",
       " '6x17',\n",
       " '6x18',\n",
       " '6x19',\n",
       " '6x20',\n",
       " '6x21',\n",
       " '6x22',\n",
       " '6x23',\n",
       " '6x24',\n",
       " '6x25',\n",
       " '6x26',\n",
       " '6x27',\n",
       " '6x28',\n",
       " '7x1',\n",
       " '7x2',\n",
       " '7x3',\n",
       " '7x4',\n",
       " '7x5',\n",
       " '7x6',\n",
       " '7x7',\n",
       " '7x8',\n",
       " '7x9',\n",
       " '7x10',\n",
       " '7x11',\n",
       " '7x12',\n",
       " '7x13',\n",
       " '7x14',\n",
       " '7x15',\n",
       " '7x16',\n",
       " '7x17',\n",
       " '7x18',\n",
       " '7x19',\n",
       " '7x20',\n",
       " '7x21',\n",
       " '7x22',\n",
       " '7x23',\n",
       " '7x24',\n",
       " '7x25',\n",
       " '7x26',\n",
       " '7x27',\n",
       " '7x28',\n",
       " '8x1',\n",
       " '8x2',\n",
       " '8x3',\n",
       " '8x4',\n",
       " '8x5',\n",
       " '8x6',\n",
       " '8x7',\n",
       " '8x8',\n",
       " '8x9',\n",
       " '8x10',\n",
       " '8x11',\n",
       " '8x12',\n",
       " '8x13',\n",
       " '8x14',\n",
       " '8x15',\n",
       " '8x16',\n",
       " '8x17',\n",
       " '8x18',\n",
       " '8x19',\n",
       " '8x20',\n",
       " '8x21',\n",
       " '8x22',\n",
       " '8x23',\n",
       " '8x24',\n",
       " '8x25',\n",
       " '8x26',\n",
       " '8x27',\n",
       " '8x28',\n",
       " '9x1',\n",
       " '9x2',\n",
       " '9x3',\n",
       " '9x4',\n",
       " '9x5',\n",
       " '9x6',\n",
       " '9x7',\n",
       " '9x8',\n",
       " '9x9',\n",
       " '9x10',\n",
       " '9x11',\n",
       " '9x12',\n",
       " '9x13',\n",
       " '9x14',\n",
       " '9x15',\n",
       " '9x16',\n",
       " '9x17',\n",
       " '9x18',\n",
       " '9x19',\n",
       " '9x20',\n",
       " '9x21',\n",
       " '9x22',\n",
       " '9x23',\n",
       " '9x24',\n",
       " '9x25',\n",
       " '9x26',\n",
       " '9x27',\n",
       " '9x28',\n",
       " '10x1',\n",
       " '10x2',\n",
       " '10x3',\n",
       " '10x4',\n",
       " '10x5',\n",
       " '10x6',\n",
       " '10x7',\n",
       " '10x8',\n",
       " '10x9',\n",
       " '10x10',\n",
       " '10x11',\n",
       " '10x12',\n",
       " '10x13',\n",
       " '10x14',\n",
       " '10x15',\n",
       " '10x16',\n",
       " '10x17',\n",
       " '10x18',\n",
       " '10x19',\n",
       " '10x20',\n",
       " '10x21',\n",
       " '10x22',\n",
       " '10x23',\n",
       " '10x24',\n",
       " '10x25',\n",
       " '10x26',\n",
       " '10x27',\n",
       " '10x28',\n",
       " '11x1',\n",
       " '11x2',\n",
       " '11x3',\n",
       " '11x4',\n",
       " '11x5',\n",
       " '11x6',\n",
       " '11x7',\n",
       " '11x8',\n",
       " '11x9',\n",
       " '11x10',\n",
       " '11x11',\n",
       " '11x12',\n",
       " '11x13',\n",
       " '11x14',\n",
       " '11x15',\n",
       " '11x16',\n",
       " '11x17',\n",
       " '11x18',\n",
       " '11x19',\n",
       " '11x20',\n",
       " '11x21',\n",
       " '11x22',\n",
       " '11x23',\n",
       " '11x24',\n",
       " '11x25',\n",
       " '11x26',\n",
       " '11x27',\n",
       " '11x28',\n",
       " '12x1',\n",
       " '12x2',\n",
       " '12x3',\n",
       " '12x4',\n",
       " '12x5',\n",
       " '12x6',\n",
       " '12x7',\n",
       " '12x8',\n",
       " '12x9',\n",
       " '12x10',\n",
       " '12x11',\n",
       " '12x12',\n",
       " '12x13',\n",
       " '12x14',\n",
       " '12x15',\n",
       " '12x16',\n",
       " '12x17',\n",
       " '12x18',\n",
       " '12x19',\n",
       " '12x20',\n",
       " '12x21',\n",
       " '12x22',\n",
       " '12x23',\n",
       " '12x24',\n",
       " '12x25',\n",
       " '12x26',\n",
       " '12x27',\n",
       " '12x28',\n",
       " '13x1',\n",
       " '13x2',\n",
       " '13x3',\n",
       " '13x4',\n",
       " '13x5',\n",
       " '13x6',\n",
       " '13x7',\n",
       " '13x8',\n",
       " '13x9',\n",
       " '13x10',\n",
       " '13x11',\n",
       " '13x12',\n",
       " '13x13',\n",
       " '13x14',\n",
       " '13x15',\n",
       " '13x16',\n",
       " '13x17',\n",
       " '13x18',\n",
       " '13x19',\n",
       " '13x20',\n",
       " '13x21',\n",
       " '13x22',\n",
       " '13x23',\n",
       " '13x24',\n",
       " '13x25',\n",
       " '13x26',\n",
       " '13x27',\n",
       " '13x28',\n",
       " '14x1',\n",
       " '14x2',\n",
       " '14x3',\n",
       " '14x4',\n",
       " '14x5',\n",
       " '14x6',\n",
       " '14x7',\n",
       " '14x8',\n",
       " '14x9',\n",
       " '14x10',\n",
       " '14x11',\n",
       " '14x12',\n",
       " '14x13',\n",
       " '14x14',\n",
       " '14x15',\n",
       " '14x16',\n",
       " '14x17',\n",
       " '14x18',\n",
       " '14x19',\n",
       " '14x20',\n",
       " '14x21',\n",
       " '14x22',\n",
       " '14x23',\n",
       " '14x24',\n",
       " '14x25',\n",
       " '14x26',\n",
       " '14x27',\n",
       " '14x28',\n",
       " '15x1',\n",
       " '15x2',\n",
       " '15x3',\n",
       " '15x4',\n",
       " '15x5',\n",
       " '15x6',\n",
       " '15x7',\n",
       " '15x8',\n",
       " '15x9',\n",
       " '15x10',\n",
       " '15x11',\n",
       " '15x12',\n",
       " '15x13',\n",
       " '15x14',\n",
       " '15x15',\n",
       " '15x16',\n",
       " '15x17',\n",
       " '15x18',\n",
       " '15x19',\n",
       " '15x20',\n",
       " '15x21',\n",
       " '15x22',\n",
       " '15x23',\n",
       " '15x24',\n",
       " '15x25',\n",
       " '15x26',\n",
       " '15x27',\n",
       " '15x28',\n",
       " '16x1',\n",
       " '16x2',\n",
       " '16x3',\n",
       " '16x4',\n",
       " '16x5',\n",
       " '16x6',\n",
       " '16x7',\n",
       " '16x8',\n",
       " '16x9',\n",
       " '16x10',\n",
       " '16x11',\n",
       " '16x12',\n",
       " '16x13',\n",
       " '16x14',\n",
       " '16x15',\n",
       " '16x16',\n",
       " '16x17',\n",
       " '16x18',\n",
       " '16x19',\n",
       " '16x20',\n",
       " '16x21',\n",
       " '16x22',\n",
       " '16x23',\n",
       " '16x24',\n",
       " '16x25',\n",
       " '16x26',\n",
       " '16x27',\n",
       " '16x28',\n",
       " '17x1',\n",
       " '17x2',\n",
       " '17x3',\n",
       " '17x4',\n",
       " '17x5',\n",
       " '17x6',\n",
       " '17x7',\n",
       " '17x8',\n",
       " '17x9',\n",
       " '17x10',\n",
       " '17x11',\n",
       " '17x12',\n",
       " '17x13',\n",
       " '17x14',\n",
       " '17x15',\n",
       " '17x16',\n",
       " '17x17',\n",
       " '17x18',\n",
       " '17x19',\n",
       " '17x20',\n",
       " '17x21',\n",
       " '17x22',\n",
       " '17x23',\n",
       " '17x24',\n",
       " '17x25',\n",
       " '17x26',\n",
       " '17x27',\n",
       " '17x28',\n",
       " '18x1',\n",
       " '18x2',\n",
       " '18x3',\n",
       " '18x4',\n",
       " '18x5',\n",
       " '18x6',\n",
       " '18x7',\n",
       " '18x8',\n",
       " '18x9',\n",
       " '18x10',\n",
       " '18x11',\n",
       " '18x12',\n",
       " '18x13',\n",
       " '18x14',\n",
       " '18x15',\n",
       " '18x16',\n",
       " '18x17',\n",
       " '18x18',\n",
       " '18x19',\n",
       " '18x20',\n",
       " '18x21',\n",
       " '18x22',\n",
       " '18x23',\n",
       " '18x24',\n",
       " '18x25',\n",
       " '18x26',\n",
       " '18x27',\n",
       " '18x28',\n",
       " '19x1',\n",
       " '19x2',\n",
       " '19x3',\n",
       " '19x4',\n",
       " '19x5',\n",
       " '19x6',\n",
       " '19x7',\n",
       " '19x8',\n",
       " '19x9',\n",
       " '19x10',\n",
       " '19x11',\n",
       " '19x12',\n",
       " '19x13',\n",
       " '19x14',\n",
       " '19x15',\n",
       " '19x16',\n",
       " '19x17',\n",
       " '19x18',\n",
       " '19x19',\n",
       " '19x20',\n",
       " '19x21',\n",
       " '19x22',\n",
       " '19x23',\n",
       " '19x24',\n",
       " '19x25',\n",
       " '19x26',\n",
       " '19x27',\n",
       " '19x28',\n",
       " '20x1',\n",
       " '20x2',\n",
       " '20x3',\n",
       " '20x4',\n",
       " '20x5',\n",
       " '20x6',\n",
       " '20x7',\n",
       " '20x8',\n",
       " '20x9',\n",
       " '20x10',\n",
       " '20x11',\n",
       " '20x12',\n",
       " '20x13',\n",
       " '20x14',\n",
       " '20x15',\n",
       " '20x16',\n",
       " '20x17',\n",
       " '20x18',\n",
       " '20x19',\n",
       " '20x20',\n",
       " '20x21',\n",
       " '20x22',\n",
       " '20x23',\n",
       " '20x24',\n",
       " '20x25',\n",
       " '20x26',\n",
       " '20x27',\n",
       " '20x28',\n",
       " '21x1',\n",
       " '21x2',\n",
       " '21x3',\n",
       " '21x4',\n",
       " '21x5',\n",
       " '21x6',\n",
       " '21x7',\n",
       " '21x8',\n",
       " '21x9',\n",
       " '21x10',\n",
       " '21x11',\n",
       " '21x12',\n",
       " '21x13',\n",
       " '21x14',\n",
       " '21x15',\n",
       " '21x16',\n",
       " '21x17',\n",
       " '21x18',\n",
       " '21x19',\n",
       " '21x20',\n",
       " '21x21',\n",
       " '21x22',\n",
       " '21x23',\n",
       " '21x24',\n",
       " '21x25',\n",
       " '21x26',\n",
       " '21x27',\n",
       " '21x28',\n",
       " '22x1',\n",
       " '22x2',\n",
       " '22x3',\n",
       " '22x4',\n",
       " '22x5',\n",
       " '22x6',\n",
       " '22x7',\n",
       " '22x8',\n",
       " '22x9',\n",
       " '22x10',\n",
       " '22x11',\n",
       " '22x12',\n",
       " '22x13',\n",
       " '22x14',\n",
       " '22x15',\n",
       " '22x16',\n",
       " '22x17',\n",
       " '22x18',\n",
       " '22x19',\n",
       " '22x20',\n",
       " '22x21',\n",
       " '22x22',\n",
       " '22x23',\n",
       " '22x24',\n",
       " '22x25',\n",
       " '22x26',\n",
       " '22x27',\n",
       " '22x28',\n",
       " '23x1',\n",
       " '23x2',\n",
       " '23x3',\n",
       " '23x4',\n",
       " '23x5',\n",
       " '23x6',\n",
       " '23x7',\n",
       " '23x8',\n",
       " '23x9',\n",
       " '23x10',\n",
       " '23x11',\n",
       " '23x12',\n",
       " '23x13',\n",
       " '23x14',\n",
       " '23x15',\n",
       " '23x16',\n",
       " '23x17',\n",
       " '23x18',\n",
       " '23x19',\n",
       " '23x20',\n",
       " '23x21',\n",
       " '23x22',\n",
       " '23x23',\n",
       " '23x24',\n",
       " '23x25',\n",
       " '23x26',\n",
       " '23x27',\n",
       " '23x28',\n",
       " '24x1',\n",
       " '24x2',\n",
       " '24x3',\n",
       " '24x4',\n",
       " '24x5',\n",
       " '24x6',\n",
       " '24x7',\n",
       " '24x8',\n",
       " '24x9',\n",
       " '24x10',\n",
       " '24x11',\n",
       " '24x12',\n",
       " '24x13',\n",
       " '24x14',\n",
       " '24x15',\n",
       " '24x16',\n",
       " '24x17',\n",
       " '24x18',\n",
       " '24x19',\n",
       " '24x20',\n",
       " '24x21',\n",
       " '24x22',\n",
       " '24x23',\n",
       " '24x24',\n",
       " '24x25',\n",
       " '24x26',\n",
       " '24x27',\n",
       " '24x28',\n",
       " '25x1',\n",
       " '25x2',\n",
       " '25x3',\n",
       " '25x4',\n",
       " '25x5',\n",
       " '25x6',\n",
       " '25x7',\n",
       " '25x8',\n",
       " '25x9',\n",
       " '25x10',\n",
       " '25x11',\n",
       " '25x12',\n",
       " '25x13',\n",
       " '25x14',\n",
       " '25x15',\n",
       " '25x16',\n",
       " '25x17',\n",
       " '25x18',\n",
       " '25x19',\n",
       " '25x20',\n",
       " '25x21',\n",
       " '25x22',\n",
       " '25x23',\n",
       " '25x24',\n",
       " '25x25',\n",
       " '25x26',\n",
       " '25x27',\n",
       " '25x28',\n",
       " '26x1',\n",
       " '26x2',\n",
       " '26x3',\n",
       " '26x4',\n",
       " '26x5',\n",
       " '26x6',\n",
       " '26x7',\n",
       " '26x8',\n",
       " '26x9',\n",
       " '26x10',\n",
       " '26x11',\n",
       " '26x12',\n",
       " '26x13',\n",
       " '26x14',\n",
       " '26x15',\n",
       " '26x16',\n",
       " '26x17',\n",
       " '26x18',\n",
       " '26x19',\n",
       " '26x20',\n",
       " '26x21',\n",
       " '26x22',\n",
       " '26x23',\n",
       " '26x24',\n",
       " '26x25',\n",
       " '26x26',\n",
       " '26x27',\n",
       " '26x28',\n",
       " '27x1',\n",
       " '27x2',\n",
       " '27x3',\n",
       " '27x4',\n",
       " '27x5',\n",
       " '27x6',\n",
       " '27x7',\n",
       " '27x8',\n",
       " '27x9',\n",
       " '27x10',\n",
       " '27x11',\n",
       " '27x12',\n",
       " '27x13',\n",
       " '27x14',\n",
       " '27x15',\n",
       " '27x16',\n",
       " '27x17',\n",
       " '27x18',\n",
       " '27x19',\n",
       " '27x20',\n",
       " '27x21',\n",
       " '27x22',\n",
       " '27x23',\n",
       " '27x24',\n",
       " '27x25',\n",
       " '27x26',\n",
       " '27x27',\n",
       " '27x28',\n",
       " '28x1',\n",
       " '28x2',\n",
       " '28x3',\n",
       " '28x4',\n",
       " '28x5',\n",
       " '28x6',\n",
       " '28x7',\n",
       " '28x8',\n",
       " '28x9',\n",
       " '28x10',\n",
       " '28x11',\n",
       " '28x12',\n",
       " '28x13',\n",
       " '28x14',\n",
       " '28x15',\n",
       " '28x16',\n",
       " '28x17',\n",
       " '28x18',\n",
       " '28x19',\n",
       " '28x20',\n",
       " '28x21',\n",
       " '28x22',\n",
       " '28x23',\n",
       " '28x24',\n",
       " '28x25',\n",
       " '28x26',\n",
       " '28x27',\n",
       " '28x28',\n",
       " 'label']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cls=np.array(list(set(df[\"class\"])))\n",
    "# df[\"class\"]=df[\"class\"].apply(clscvrt, args=())\n",
    "\n",
    "cols =list(df.columns)\n",
    "cols.remove(\"label\")\n",
    "cols.append(\"label\")\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x20  28x21  \\\n",
       "0        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "1        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "2        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "3        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "4        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
       "59995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "59996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "59997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "59998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "59999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "\n",
       "       28x22  28x23  28x24  28x25  28x26  28x27  28x28  label  \n",
       "0          0      0      0      0      0      0      0      5  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      4  \n",
       "3          0      0      0      0      0      0      0      1  \n",
       "4          0      0      0      0      0      0      0      9  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      8  \n",
       "59996      0      0      0      0      0      0      0      3  \n",
       "59997      0      0      0      0      0      0      0      5  \n",
       "59998      0      0      0      0      0      0      0      6  \n",
       "59999      0      0      0      0      0      0      0      8  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiran M R\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "train, valid = np.split(df.sample(frac=1), [int(5/6*len(df))])\n",
    "print(len(train),len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3aWmmwH-RNtL"
   },
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe, oversample=False):\n",
    "  X = dataframe[dataframe.columns[:-1]].values\n",
    "  y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X = scaler.fit_transform(X)\n",
    "\n",
    "  if oversample:\n",
    "    ros = RandomOverSampler()\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "\n",
    "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "  return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j5GvQhCKRNtM"
   },
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "valid, X_valid, y_valid = scale_dataset(valid, oversample=False)\n",
    "data_tensor = torch.tensor(X_valid, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10 hidden layer model\n",
    "\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, dropout_prob):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "#         # Define the layers\n",
    "#         self.hidden1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.hidden2 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden3 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden4 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden5 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden6 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden7 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden8 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden9 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.hidden10 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.dropout = nn.Dropout(p=dropout_prob)\n",
    "#         self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "#         # Define activation function (e.g., ReLU)\n",
    "#         self.activation = nn.ReLU()\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.activation(self.hidden1(x))\n",
    "#         x = self.activation(self.hidden2(x))\n",
    "#         x = self.activation(self.hidden3(x))\n",
    "#         x = self.activation(self.hidden4(x))\n",
    "#         x = self.activation(self.hidden5(x))\n",
    "#         x = self.activation(self.hidden6(x))\n",
    "#         x = self.activation(self.hidden7(x))\n",
    "#         x = self.activation(self.hidden8(x))\n",
    "#         x = self.activation(self.hidden9(x))\n",
    "#         x = self.activation(self.hidden10(x))\n",
    "#         #x = torch.softmax(self.output_layer(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.output(x)\n",
    "#         x=nn.Softmax(dim=1)(x)\n",
    "#         return x\n",
    "\n",
    "# # Define the input size, hidden size, and output size\n",
    "# input_size = len(df.columns)-1  # Change this to match the dimension of your input data)\n",
    "# hidden_size = 32  # Number of neurons in each hidden layer\n",
    "# output_size = 3  # Number of output nodes\n",
    "\n",
    "# # Create an instance of the neural network\n",
    "# model = NeuralNetwork(input_size, hidden_size, output_size,0.0)\n",
    "\n",
    "# # You can now use this model for training and making predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(one_hot_labels)):\n",
    "    if (np.where(one_hot_labels[e]==max(one_hot_labels[e]))[0][0] == y_train[e]):\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\machine_learning\\Image_recognition\\image_rec.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model \u001b[39m=\u001b[39m NeuralNetwork(input_size, hidden_size, output_size,dropout_prob)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X31sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m loss_function \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()  \u001b[39m# For classification, adjdropout_probt for your specific problemx\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X31sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m data_tensor\u001b[39m=\u001b[39mX_train\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X31sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m learning_rate\u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X31sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 2 hidden layer model\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_prob):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden2 = nn.Linear(int(hidden_size), hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Define activation function (e.g., ReLU)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden1(x))\n",
    "        x = self.activation(self.hidden2(x))\n",
    "    \n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        x = F.softmax(x, dim=1)  # Use nn.functional.softmax.to(device)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the input size, hidden size, and output size\n",
    "input_size = len(df.columns)-1  # Change this to match the dimension of your input data)\n",
    "hidden_size = 64  # Number of neurons in each hidden layer\n",
    "output_size = 10  # Number of output nodes\n",
    "dropout_prob = 0.19\n",
    "d_p = dropout_prob\n",
    "\n",
    "# Create an instance of the neural network\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size,dropout_prob).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()  # For classification, adjdropout_probt for your specific problemx\n",
    "\n",
    "data_tensor=X_train\n",
    "learning_rate= 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "one_hot_labels=np.eye(10)[y_train]\n",
    "features_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "c,m=0,0\n",
    "tim = time.ctime()\n",
    "tim=tim[11:19]+ '_'+ tim[20:]\n",
    "name=\"model_data_\" + tim.replace(':', '.') + \".txt\"\n",
    "\n",
    "with open(name, \"a\") as f:\n",
    "    f.write(\"Accuracy (%), Epoch No., Dropout Probability, Learning Rate\\n\")\n",
    "    f.write(f'0, 0,{dropout_prob},{learning_rate}\\n' )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = time.ctime()\n",
    "tim=tim[11:19]+ '_'+ tim[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size =1024  # Adjust the batch size as needed\n",
    "shuffle = True   # Set to True if you want to shuffle the data during each epoch\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_epochs = 450  # Adjust the number of training epochs as needed\n",
    "# print(\"Multiplier:\", c+1)\n",
    "# for epoch in range(num_epochs-m):\n",
    "    \n",
    "#     model.train()  # Set the model to training mode\n",
    "\n",
    "#     for batch_data, batch_labels in dataloader:  # dataloader is a DataLoader object with your training data\n",
    "#         optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(batch_data)\n",
    "#         loss = loss_function(outputs, batch_labels)\n",
    "\n",
    "#         # Backpropagation\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Print or log the loss for this epoch\n",
    "#     print(f'Epoch [{c*num_epochs+m+1}/{num_epochs*(c+1)}], Loss: {loss.item()}')\n",
    "\n",
    "#     # After training, save the model or use it for predictions\n",
    "#     torch.save(model.state_dict(), 'your_model.pth')\n",
    "#     m+=1\n",
    "\n",
    "# #print(\"Actual no. of epoch =\",c*num_epochs+epoch+1)\n",
    "# c+=1\n",
    "# m=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tensor = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "# chumma = 0\n",
    "# Nt=10\n",
    "# for i in range(Nt):\n",
    "#     pred=model(data_tensor)\n",
    "#     pred=pred.to('cpu')\n",
    "#     pred=pred.detach().numpy()\n",
    "#     prediction=pred.copy()\n",
    "#     i=0\n",
    "#     ind=np.arange(3)\n",
    "#     index=[]\n",
    "#     for a in prediction:\n",
    "#         pred[i]=np.array([0,0,0])\n",
    "#         #print(a)\n",
    "#         max_ind=np.argmax(a)\n",
    "#         index.append(max_ind)\n",
    "\n",
    "#         #print(max_ind)\n",
    "#         pred[i][max_ind]=1\n",
    "#         #print(pred[i])\n",
    "#         i+=1\n",
    "        \n",
    "#     count=0\n",
    "#     for i in range(len(pred)):\n",
    "#         if index[i] == y_valid[i]:\n",
    "#             count+=1\n",
    "#     chumma += count/len(pred)\n",
    "#     print(count/len(pred))\n",
    "# print(f'Average is (%) = {chumma/Nt*100} (epoch = {c*num_epochs+m})')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\machine_learning\\Image_recognition\\image_rec.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(X_valid, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m450\u001b[39m  \u001b[39m# Adjust the number of training epochs as needed\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMultiplier:\u001b[39m\u001b[39m\"\u001b[39m, c\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "num_epochs = 450  # Adjust the number of training epochs as needed\n",
    "print(\"Multiplier:\", c+1)\n",
    "\n",
    "#now_loss = loss.item()\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for batch_data, batch_labels in dataloader:  # dataloader is a DataLoader object with your training data\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(batch_data)\n",
    "    loss = loss_function(outputs, batch_labels)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    now_loss = loss.item()\n",
    "\n",
    "for epoch in range(1,num_epochs-m):\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for batch_data, batch_labels in dataloader:  # dataloader is a DataLoader object with your training data\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        loss = loss_function(outputs, batch_labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    pre_loss = now_loss\n",
    "    now_loss = loss.item()\n",
    "    \n",
    "    if (now_loss > pre_loss and now_loss <0.5):\n",
    "        learning_rate = learning_rate * 0.999\n",
    "        d_p = d_p * 1.005\n",
    "    else:\n",
    "        learning_rate = learning_rate * 1.0005\n",
    "        d_p = d_p * 0.9995\n",
    "\n",
    "\n",
    "    model.dropout.p = d_p\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # model=new_model\n",
    "    # new_model = NeuralNetwork(input_size, hidden_size, output_size,d_p_new).to(device)\n",
    "    # # Copy the weights from the pre-trained model to the new model\n",
    "    # new_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    # optimizer = torch.optim.SGD(new_model.parameters(), lr=lr_new)\n",
    "\n",
    "    # Print or log the loss for this epoch\n",
    "    curr_epo=c*num_epochs+m+1\n",
    "    print(f'Epoch [{curr_epo}/{num_epochs*(c+1)}], Loss: {loss.item()}')\n",
    "\n",
    "    # After training, save the model or use it for predictions\n",
    "    torch.save(model.state_dict(), 'your_model.pth')\n",
    "\n",
    "\n",
    "    if((curr_epo)%20<0.1):\n",
    "        ##data_tensor = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "\n",
    "        cx = 0\n",
    "        Nt=10\n",
    "        for k in range(Nt):\n",
    "            pred=model(data_tensor)\n",
    "            pred=pred.to('cpu')\n",
    "            pred=pred.detach().numpy()\n",
    "            prediction=pred.copy()\n",
    "            i=0\n",
    "            index=[]\n",
    "            for a in prediction:\n",
    "                pred[i]=np.zeros(10)\n",
    "                #print(a)\n",
    "                max_ind=np.argmax(a)\n",
    "                index.append(max_ind)\n",
    "\n",
    "                #print(max_ind)\n",
    "                pred[i][max_ind]=1\n",
    "                #print(pred[i])\n",
    "                i+=1\n",
    "            seriyavatha_index = []  \n",
    "            count=0\n",
    "            for q in range(len(pred)):\n",
    "                if index[q] == y_valid[q]:\n",
    "                    count+=1\n",
    "                elif k == Nt:\n",
    "                    seriyavatha_index.append(q)\n",
    "            cx += count/len(pred)\n",
    "            #print(count/len(pred))\n",
    "        print(f'Average is (%) = {cx/Nt*100} (epoch = {curr_epo})')\n",
    "        with open(name, \"a\") as f:\n",
    "            f.write(f'{cx/Nt*100},{curr_epo},{d_p},{learning_rate})\\n')\n",
    "\n",
    "    m+=1\n",
    "\n",
    "#print(\"Actual no. of epoch =\",c*num_epochs+epoch+1)\n",
    "c+=1\n",
    "m=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (hidden1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (hidden2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.010301559888315062, inplace=False)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(input_size, hidden_size, output_size,0.010301559888315062).to(device)\n",
    "model.load_state_dict(torch.load('your_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\machine_learning\\Image_recognition\\image_rec.ipynb Cell 30\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#Y123sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39myour_model.pth\u001b[39m\u001b[39m'\u001b[39m, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#Y123sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine_learning/Image_recognition/image_rec.ipynb#Y123sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49meval()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = torch.load('your_model.pth', map_location='cpu')\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= pd.read_csv(\"mnist_test.csv\")\n",
    "df_test=df_test[cols]\n",
    "test, X_test, y_test = scale_dataset(df_test, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8734524e-11 1.0432565e-11 1.7782051e-13 ... 1.0000000e+00\n",
      "  7.1541013e-15 2.9073233e-10]\n",
      " [5.2873669e-17 1.4705744e-14 1.0000000e+00 ... 3.6734479e-18\n",
      "  2.3770729e-18 2.9539843e-26]\n",
      " [1.3146395e-07 9.9990344e-01 7.4422564e-06 ... 1.5099377e-05\n",
      "  3.8790819e-05 2.4970692e-08]\n",
      " ...\n",
      " [1.8254178e-18 2.6345400e-14 1.4237332e-16 ... 2.5588076e-14\n",
      "  2.0871430e-11 5.4254962e-10]\n",
      " [1.2230220e-14 2.8062127e-18 1.6715713e-21 ... 1.0240407e-18\n",
      "  1.5436679e-07 2.7538831e-11]\n",
      " [4.7421633e-12 7.2658116e-17 2.7725416e-14 ... 7.2086395e-16\n",
      "  1.3552216e-18 1.7056517e-22]]\n",
      "96.71\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "pred=model(data_tensor)\n",
    "pred=pred.to('cpu')\n",
    "pred=pred.detach().numpy()\n",
    "prediction=pred.copy()\n",
    "print(prediction)\n",
    "i=0\n",
    "index=[]\n",
    "for a in prediction:\n",
    "    pred[i]=np.zeros(10)\n",
    "    #print(a)\n",
    "    max_ind=np.argmax(a)\n",
    "    index.append(max_ind)\n",
    "\n",
    "    #print(max_ind)\n",
    "    pred[i][max_ind]=1\n",
    "    #print(pred[i])\n",
    "    i+=1\n",
    "    seriyavatha_index = []  \n",
    "    count=0\n",
    "    #print(len(prediction))\n",
    "    #print(\"index = \",(index))\n",
    "for q in range(len(prediction)):\n",
    "        # print(q)\n",
    "    if index[q] != y_test[q]:\n",
    "        seriyavatha_index.append(q)\n",
    "\n",
    "print((len(prediction)-len(seriyavatha_index))/len(pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9015"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seriyavatha_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44,\n",
       " 282,\n",
       " 475,\n",
       " 497,\n",
       " 553,\n",
       " 581,\n",
       " 602,\n",
       " 695,\n",
       " 749,\n",
       " 782,\n",
       " 792,\n",
       " 796,\n",
       " 874,\n",
       " 909,\n",
       " 961,\n",
       " 1010,\n",
       " 1049,\n",
       " 1152,\n",
       " 1222,\n",
       " 1408,\n",
       " 1465,\n",
       " 1704,\n",
       " 1711,\n",
       " 1720,\n",
       " 1741,\n",
       " 1750,\n",
       " 1871,\n",
       " 1986,\n",
       " 2106,\n",
       " 2116,\n",
       " 2125,\n",
       " 2368,\n",
       " 2503,\n",
       " 2545,\n",
       " 2697,\n",
       " 2804,\n",
       " 2827,\n",
       " 2965,\n",
       " 3025,\n",
       " 3118,\n",
       " 3200,\n",
       " 3224,\n",
       " 3252,\n",
       " 3296,\n",
       " 3306,\n",
       " 3353,\n",
       " 3377,\n",
       " 3605,\n",
       " 3849,\n",
       " 3901,\n",
       " 3920,\n",
       " 3984,\n",
       " 4007,\n",
       " 4141,\n",
       " 4161,\n",
       " 4293,\n",
       " 4338,\n",
       " 4417,\n",
       " 4629,\n",
       " 4639,\n",
       " 4766,\n",
       " 4783,\n",
       " 4837,\n",
       " 5083,\n",
       " 5090,\n",
       " 5118,\n",
       " 5127,\n",
       " 5326,\n",
       " 5339,\n",
       " 5346,\n",
       " 5482,\n",
       " 5529,\n",
       " 5679,\n",
       " 5689,\n",
       " 5761,\n",
       " 5942,\n",
       " 6062,\n",
       " 6106,\n",
       " 6217,\n",
       " 6323,\n",
       " 6405,\n",
       " 6438,\n",
       " 6440,\n",
       " 6449,\n",
       " 6640,\n",
       " 6771,\n",
       " 6810,\n",
       " 6929,\n",
       " 6975,\n",
       " 7016,\n",
       " 7149,\n",
       " 7157,\n",
       " 7248,\n",
       " 7278,\n",
       " 7287,\n",
       " 7316,\n",
       " 7374,\n",
       " 7425,\n",
       " 7544,\n",
       " 7628,\n",
       " 7670,\n",
       " 7710,\n",
       " 7766,\n",
       " 7988,\n",
       " 8004,\n",
       " 8036,\n",
       " 8098,\n",
       " 8145,\n",
       " 8395,\n",
       " 8397,\n",
       " 8609,\n",
       " 8685,\n",
       " 8777,\n",
       " 8948,\n",
       " 9012,\n",
       " 9129,\n",
       " 9275,\n",
       " 9290,\n",
       " 9308,\n",
       " 9362,\n",
       " 9444,\n",
       " 9713]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriyavatha_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.00005000e-02,\n",
       "       -1.50569941e-02, -2.08415144e-02, -3.35956355e-02, -3.90764292e-02,\n",
       "       -4.11755570e-02, -3.77639845e-02, -2.97887932e-02, -2.71279202e-02,\n",
       "       -3.09015909e-02, -3.10889675e-02, -2.94205646e-02, -2.28962748e-02,\n",
       "       -1.90509469e-02, -1.64526251e-02, -1.51102177e-02, -1.00005000e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.40946851e-02, -1.40935068e-02, -1.69055159e-02, -2.78341511e-02,\n",
       "       -3.97556712e-02, -6.07969255e-02, -7.19377614e-02, -8.41464666e-02,\n",
       "       -1.05322676e-01, -1.20698344e-01, -1.32202083e-01, -1.41743521e-01,\n",
       "       -1.40277772e-01, -1.34519791e-01, -1.27396103e-01, -1.07790569e-01,\n",
       "       -8.48204386e-02, -6.21745082e-02, -4.30642739e-02, -2.44871141e-02,\n",
       "       -1.45973918e-02, -1.00005000e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.77809677e-02, -1.40893683e-02, -2.27360796e-02, -5.09811770e-02,\n",
       "       -7.89039360e-02, -1.07916772e-01, -1.33663655e-01, -1.63145304e-01,\n",
       "       -1.99024234e-01, -2.29160081e-01, -2.51424175e-01, -2.64907724e-01,\n",
       "       -2.63241526e-01, -2.48792141e-01, -2.23302887e-01, -1.89649050e-01,\n",
       "       -1.51348949e-01, -1.12346057e-01, -7.80083043e-02, -4.20612428e-02,\n",
       "       -2.72775231e-02, -1.01909527e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.00005000e-02, -1.63530859e-02,\n",
       "       -2.63365941e-02, -4.24574398e-02, -6.73390130e-02, -1.08636242e-01,\n",
       "       -1.55513346e-01, -2.11424338e-01, -2.66400155e-01, -3.30196030e-01,\n",
       "       -3.97605162e-01, -4.61258342e-01, -5.06694932e-01, -5.29560956e-01,\n",
       "       -5.19551932e-01, -4.79139433e-01, -4.25036548e-01, -3.57988212e-01,\n",
       "       -2.83093119e-01, -2.19767105e-01, -1.59192524e-01, -1.04208304e-01,\n",
       "       -6.48686275e-02, -3.95579946e-02, -1.37257286e-02, -1.00005000e-02,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.72248966e-02, -1.82895180e-02,\n",
       "       -4.65007441e-02, -8.01881821e-02, -1.30883185e-01, -1.91632871e-01,\n",
       "       -2.61097238e-01, -3.38567606e-01, -4.23396706e-01, -5.20286794e-01,\n",
       "       -6.18535925e-01, -7.19294487e-01, -8.01694892e-01, -8.38563727e-01,\n",
       "       -8.27732790e-01, -7.61864989e-01, -6.68926644e-01, -5.61534923e-01,\n",
       "       -4.48225804e-01, -3.51222549e-01, -2.59881924e-01, -1.93263195e-01,\n",
       "       -1.33944695e-01, -7.56796047e-02, -2.72442102e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.00005000e-02, -2.24528313e-02, -3.82708534e-02,\n",
       "       -7.87814466e-02, -1.27331038e-01, -1.91084474e-01, -2.66265232e-01,\n",
       "       -3.58274853e-01,  4.51672149e-01,  2.14653774e+00,  1.78606619e+00,\n",
       "        1.79866333e-01, -8.28583633e-01, -1.06537231e+00, -1.11392924e+00,\n",
       "       -1.08972963e+00, -1.00560417e+00, -8.78053396e-01, -7.27756016e-01,\n",
       "       -5.79768685e-01, -4.48741849e-01, -3.37467209e-01, -2.47757147e-01,\n",
       "       -1.74546594e-01, -1.06685219e-01, -4.71109068e-02, -1.98427070e-02,\n",
       "        0.00000000e+00, -1.43054092e-02, -2.85927547e-02, -6.76786747e-02,\n",
       "       -1.17907805e-01, -1.79549723e-01, -2.57068727e-01, -3.52968726e-01,\n",
       "       -4.59426825e-01, -2.27184799e-02,  1.13831717e+00,  1.45887820e+00,\n",
       "        1.27949583e+00,  8.71237218e-01,  7.63718017e-01,  7.42207760e-01,\n",
       "        2.01106343e-01, -4.87817313e-01,  5.60420804e-01,  1.12645871e+00,\n",
       "        4.13682355e-02,  6.48022577e-02, -3.96947309e-01, -2.86264098e-01,\n",
       "       -1.93772668e-01, -1.22150179e-01, -6.26494330e-02, -2.18328135e-02,\n",
       "        0.00000000e+00, -2.14012106e-02, -4.55428077e-02, -9.57286211e-02,\n",
       "       -1.45292273e-01, -2.14001067e-01, -2.98929546e-01, -4.07840748e-01,\n",
       "       -5.36720374e-01, -6.88140852e-01, -7.50086663e-01,  3.89063619e-01,\n",
       "        8.57531457e-01,  1.09955240e+00,  1.16815153e+00,  1.17832562e+00,\n",
       "        1.17059093e+00,  1.16399171e+00,  1.21993013e+00,  1.37589202e+00,\n",
       "        1.71061362e+00,  1.95516673e+00,  5.51738632e-01, -2.89144124e-01,\n",
       "       -1.93390782e-01, -1.16890397e-01, -5.73785315e-02, -1.39153688e-02,\n",
       "        0.00000000e+00, -2.41700084e-02, -5.20243453e-02, -9.79460900e-02,\n",
       "       -1.51467145e-01, -2.24607673e-01, -3.19061882e-01, -4.39192864e-01,\n",
       "       -5.83064101e-01, -7.50019308e-01, -9.13214121e-01, -1.00285437e+00,\n",
       "       -1.00066477e+00, -9.94904938e-02,  2.83871274e-01,  1.42065646e+00,\n",
       "        1.35560247e+00,  1.27058613e+00,  1.26195728e+00,  1.40078942e+00,\n",
       "        1.72271430e+00,  2.19218388e+00,  2.50931023e+00, -2.82947984e-01,\n",
       "       -1.76610687e-01, -1.00263902e-01, -4.90827852e-02,  0.00000000e+00,\n",
       "       -1.00005000e-02, -2.40678119e-02, -5.45340602e-02, -9.27605667e-02,\n",
       "       -1.41919800e-01, -2.23453591e-01, -3.27677539e-01, -4.62679139e-01,\n",
       "       -6.15459367e-01, -7.88011537e-01, -9.22700815e-01, -9.44966888e-01,\n",
       "       -8.78015498e-01, -7.91006663e-01, -7.62263422e-01, -7.97718090e-01,\n",
       "        1.41787229e-01,  1.33959298e+00,  1.31158204e+00,  1.44909987e+00,\n",
       "        1.81604947e+00,  1.94672058e+00,  1.36995910e+00, -2.61764383e-01,\n",
       "       -1.55815298e-01, -8.10844120e-02, -3.98458532e-02,  0.00000000e+00,\n",
       "       -1.40994604e-02, -2.80158625e-02, -5.00220740e-02, -8.46413784e-02,\n",
       "       -1.38041603e-01, -2.21638971e-01, -3.34871399e-01, -4.82521865e-01,\n",
       "       -6.46512535e-01, -8.13793274e-01, -9.10407767e-01, -8.85628891e-01,\n",
       "       -7.91405725e-01, -7.29432233e-01, -2.39789052e-02,  1.23648699e+00,\n",
       "        1.24996830e+00,  1.30829105e+00,  1.21794492e+00,  8.28626944e-01,\n",
       "        5.63105029e-01, -1.94017783e-01, -3.61922840e-01, -2.52058848e-01,\n",
       "       -1.44629645e-01, -6.17806071e-02, -2.25685779e-02, -1.00005000e-02,\n",
       "       -1.00005000e-02, -2.12431360e-02, -3.78653196e-02, -6.76192204e-02,\n",
       "       -1.28137734e-01, -2.24971810e-01, -3.51105453e-01, -5.08072428e-01,\n",
       "       -6.75022379e-01, -8.36811401e-01, -9.03341686e-01, -8.58389405e-01,\n",
       "       -6.17483322e-01,  7.99769582e-01,  1.31111816e+00,  1.34312501e+00,\n",
       "        1.25219797e+00,  9.07455753e-01, -5.33201601e-02, -7.97676196e-01,\n",
       "       -6.13920580e-01, -4.62321813e-01, -3.53576052e-01, -2.52915597e-01,\n",
       "       -1.48137905e-01, -5.44210027e-02, -2.03543495e-02, -1.00005000e-02,\n",
       "        0.00000000e+00, -1.20472062e-02, -2.58811372e-02, -5.71899317e-02,\n",
       "       -1.24928795e-01, -2.35703414e-01, -3.71761048e-01, -5.33845306e-01,\n",
       "       -7.00142237e-01, -8.43509697e-01, -8.96229599e-01, -8.49315974e-01,\n",
       "        9.70020070e-01,  1.43031156e+00,  1.22932612e+00,  1.13304823e+00,\n",
       "        5.36758386e-01, -1.00633700e+00, -9.84450507e-01, -7.82677889e-01,\n",
       "       -5.90096448e-01, -4.57023943e-01, -3.53160113e-01, -2.63820996e-01,\n",
       "       -1.57455875e-01, -6.09617256e-02, -2.56217389e-02, -1.00005000e-02,\n",
       "        0.00000000e+00, -1.00005000e-02, -1.56360956e-02, -4.86776289e-02,\n",
       "       -1.27552270e-01, -2.55052304e-01, -3.89244520e-01, -5.49630710e-01,\n",
       "       -7.11763295e-01, -8.37232703e-01, -8.78918200e-01, -8.67555298e-01,\n",
       "        1.43633065e+00,  1.23339739e+00,  2.02115717e-01, -1.28120698e+00,\n",
       "       -1.25758015e+00, -1.14701816e+00, -9.76871571e-01, -7.72198953e-01,\n",
       "       -6.00483926e-01, -4.73985853e-01, -3.65250105e-01, -2.71128010e-01,\n",
       "       -1.65813874e-01, -6.89261614e-02, -2.78818918e-02, -1.00005000e-02,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.64704708e-02, -4.78517416e-02,\n",
       "       -1.34063417e-01, -2.71953817e-01, -4.05689129e-01, -5.50714525e-01,\n",
       "       -6.92767007e-01, -7.98732852e-01, -8.50204307e-01, -8.74003534e-01,\n",
       "        9.61125701e-01,  1.14439289e+00,  6.17988677e-01, -6.02304519e-01,\n",
       "       -1.17012636e+00, -1.07996820e+00, -9.32321291e-01, -7.58925167e-01,\n",
       "       -6.12786931e-01, -4.90459393e-01, -3.78424006e-01, -2.72255892e-01,\n",
       "       -1.67194632e-01, -7.57484210e-02, -3.13761876e-02, -1.00005000e-02,\n",
       "        0.00000000e+00, -1.00005000e-02, -1.91676204e-02, -5.93719299e-02,\n",
       "       -1.47815341e-01, -2.88332323e-01, -4.14631355e-01, -5.41193343e-01,\n",
       "       -6.60139477e-01, -7.45176227e-01, -7.90857454e-01, -8.33728336e-01,\n",
       "       -6.01086289e-02,  1.16109795e+00,  1.11633044e+00,  1.13260988e+00,\n",
       "        5.59465164e-01,  6.36721537e-01, -4.08450140e-01, -7.50893679e-01,\n",
       "       -6.19909504e-01, -4.95073251e-01, -3.80738602e-01, -2.68409819e-01,\n",
       "       -1.69457266e-01, -8.19955696e-02, -3.50817314e-02, -1.22506332e-02,\n",
       "        0.00000000e+00, -1.46242053e-02, -2.44251680e-02, -7.29998567e-02,\n",
       "       -1.73423326e-01, -3.06380328e-01, -4.24057423e-01, -5.33898314e-01,\n",
       "       -6.22946235e-01, -6.80791741e-01, -7.22504931e-01, -7.56314129e-01,\n",
       "       -8.15221836e-01, -7.89810629e-02,  1.46768374e-01,  1.24078548e+00,\n",
       "        1.28507490e+00,  1.36080132e+00,  5.65835923e-01, -7.44757425e-01,\n",
       "       -6.16841268e-01, -4.84841361e-01, -3.65855376e-01, -2.59967608e-01,\n",
       "       -1.65975656e-01, -9.24637248e-02, -4.06757860e-02, -1.44757362e-02,\n",
       "        0.00000000e+00, -1.30898087e-02, -2.89288191e-02, -8.82480123e-02,\n",
       "       -1.94876360e-01, -3.20746579e-01, -4.36538285e-01, -5.32596013e-01,\n",
       "       -6.07496891e-01, -6.56388591e-01, -6.96179598e-01, -7.24040897e-01,\n",
       "       -7.73963564e-01, -8.66636020e-01, -9.52619929e-01, -1.00307867e+00,\n",
       "        1.30887529e+00,  1.35254356e+00,  1.13562415e+00, -7.36337810e-01,\n",
       "       -5.96340473e-01, -4.66048387e-01, -3.50633950e-01, -2.45673162e-01,\n",
       "       -1.55229845e-01, -8.95841764e-02, -3.21874795e-02, -1.21276730e-02,\n",
       "        0.00000000e+00, -1.28678496e-02, -3.32419601e-02, -9.99514748e-02,\n",
       "       -2.08641743e-01, -3.30806727e-01, -4.50851915e-01, -5.53343738e-01,\n",
       "       -6.32745954e-01, -6.91287522e-01, -7.34034210e-01, -7.70131242e-01,\n",
       "       -8.32742782e-01, -9.24312777e-01, -9.12821029e-01, -4.09985472e-01,\n",
       "        1.23369479e+00,  1.29241684e+00,  7.40537853e-01, -7.05207588e-01,\n",
       "       -5.58972336e-01, -4.30754890e-01, -3.21103619e-01, -2.21705244e-01,\n",
       "       -1.43794170e-01, -8.43831950e-02, -2.95744631e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.33515552e-02, -4.20923738e-02, -1.06657958e-01,\n",
       "       -2.02602376e-01, -3.24545096e-01, -4.53635171e-01, -5.68774423e-01,\n",
       "       -6.72729364e-01, -7.57029515e-01, -8.32292182e-01, -8.94166167e-01,\n",
       "       -9.77281567e-01, -4.17724329e-01,  5.83883695e-01,  1.12219804e+00,\n",
       "        1.19483840e+00,  6.61482846e-01, -6.07328616e-01, -6.31001504e-01,\n",
       "       -4.89430054e-01, -3.69322588e-01, -2.72754648e-01, -1.89896690e-01,\n",
       "       -1.22287828e-01, -7.09254520e-02, -3.10476637e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.35179913e-02, -3.87692338e-02, -1.00542068e-01,\n",
       "       -1.84266154e-01, -2.96261129e-01, -4.27028940e-01, -5.58471556e-01,\n",
       "       -6.85272285e-01, -8.00168366e-01, -9.06838587e-01, -1.01394005e+00,\n",
       "        1.90247520e-01,  9.53349091e-01,  1.08085459e+00,  1.13756145e+00,\n",
       "        7.26128695e-01, -7.01075095e-01, -6.77207921e-01, -5.25422847e-01,\n",
       "       -3.98466434e-01, -2.98142912e-01, -2.14118052e-01, -1.43855891e-01,\n",
       "       -9.76594644e-02, -5.32769121e-02, -1.83338192e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.00005000e-02, -3.34977841e-02, -7.98771396e-02,\n",
       "       -1.46913368e-01, -2.41384394e-01, -3.58979275e-01, -4.89136645e-01,\n",
       "       -6.27538189e-01,  1.17518807e-01,  2.65649453e-01,  1.23294028e+00,\n",
       "        1.17574060e+00,  8.58603198e-01,  3.64828662e-02, -9.70234828e-01,\n",
       "       -8.21943993e-01, -6.69134981e-01, -5.27411028e-01, -4.00329227e-01,\n",
       "       -3.05994246e-01, -2.23492862e-01, -1.57980963e-01, -1.08943230e-01,\n",
       "       -6.71989405e-02, -3.90769234e-02, -1.41191387e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.25892216e-02, -5.20548109e-02,\n",
       "       -1.01923413e-01, -1.67198672e-01,  9.01505172e-01,  7.62185753e-01,\n",
       "        2.12973726e+00,  1.93786307e+00,  1.65094800e+00,  1.45922588e+00,\n",
       "        7.23568241e-01, -4.97846711e-01, -8.44512523e-01, -7.40690607e-01,\n",
       "       -6.10989373e-01, -4.94201742e-01, -3.80154266e-01, -2.86928972e-01,\n",
       "       -2.18274999e-01, -1.58622912e-01, -1.15765460e-01, -7.46154318e-02,\n",
       "       -3.87524371e-02, -1.60652217e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.38688385e-02, -2.84335391e-02,\n",
       "        1.63419007e+00,  9.26839232e+00,  8.31350511e+00,  5.90859739e+00,\n",
       "        3.86765949e+00,  2.04760486e+00,  3.83771436e-01,  2.59900585e-01,\n",
       "       -5.71737516e-01, -5.69881221e-01, -5.32681329e-01, -4.70271495e-01,\n",
       "       -3.92407773e-01, -3.18492981e-01, -2.48154258e-01, -1.89387466e-01,\n",
       "       -1.47378062e-01, -1.08248933e-01, -7.51461633e-02, -5.26649569e-02,\n",
       "       -2.71325727e-02, -1.41435500e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.18950868e-02,\n",
       "        9.73507276e+00,  2.40368668e+01,  1.30306115e+01,  4.11811652e+00,\n",
       "        1.52431690e+00, -2.24459611e-01, -2.68009620e-01, -2.94736619e-01,\n",
       "       -3.09223919e-01, -3.10871686e-01, -2.94060964e-01, -2.66362995e-01,\n",
       "       -2.32132739e-01, -1.96897381e-01, -1.60791564e-01, -1.23899596e-01,\n",
       "       -9.73846372e-02, -7.44060981e-02, -5.16509582e-02, -3.40389604e-02,\n",
       "       -1.66481621e-02,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.00005000e-02,\n",
       "       -1.69007423e-02, -3.23358178e-02, -5.54909756e-02, -8.27128914e-02,\n",
       "       -1.09901594e-01, -1.30429965e-01, -1.53157051e-01, -1.69380498e-01,\n",
       "       -1.82236164e-01, -1.84723721e-01, -1.73672988e-01, -1.54822257e-01,\n",
       "       -1.36175023e-01, -1.17540311e-01, -9.15721618e-02, -6.63353323e-02,\n",
       "       -5.39391800e-02, -4.31757456e-02, -2.68233661e-02, -1.91948063e-02,\n",
       "       -1.00005000e-02, -1.00005000e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.00005000e-02, -1.27954298e-02,\n",
       "       -2.03499006e-02, -2.73364608e-02, -4.48348385e-02, -4.58607990e-02,\n",
       "       -4.90412809e-02, -5.41455077e-02, -6.20356856e-02, -6.01761359e-02,\n",
       "       -5.67790704e-02, -5.28352394e-02, -4.39640570e-02, -2.28232794e-02,\n",
       "       -1.00628129e-02, -1.22329926e-02, -1.00005000e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[seriyavatha_index[7]][784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Thettiya_y = y_valid[seriyavatha_index]\n",
    "# Thettiya_x = X_valid[seriyavatha_index]\n",
    "import matplotlib.pyplot as plt\n",
    "#naam = df.columns[:-1]\n",
    "#x=np.arange(1,28)\n",
    "\n",
    "for o in range(len(X_valid[0])):\n",
    "    if (valid[seriyavatha_index[7]][o]>.5):\n",
    "        plt.scatter((o+1)%28,int((o+1)/28)+1, color='green')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# entha type cheyyande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([1,2],[10,13])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.028\n",
    "dropout_prob = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\kiran m r\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\Kiran M R\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 255, 255, 255, 255, 255,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255,   0, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255, 255,   0,\n",
       "         0,   0,   0,   0,   0,   0, 255, 255, 255, 255,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255, 255,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255, 255,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255,\n",
       "       255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,\n",
       "       255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,\n",
       "       255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 255, 255, 255, 255,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 255, 255, 255, 255,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 255, 255, 255, 255,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255,\n",
       "       255,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255,\n",
       "       255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,\n",
       "       255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,\n",
       "       255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       255, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,\n",
       "         0, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 255, 255, 255, 255, 255,   0,   0,\n",
       "         0, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_to_matrix(image_path):\n",
    "    # Open the image file\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale (optional)\n",
    "    img = img.convert('L')\n",
    "\n",
    "    # Get the pixel data as a 2D matrix\n",
    "    pixel_matrix = list(img.getdata())\n",
    "\n",
    "    # Reshape the matrix to the image size\n",
    "    width, height = img.size\n",
    "    pixel_matrix = [pixel_matrix[i * width:(i + 1) * width] for i in range(height)]\n",
    "\n",
    "    return pixel_matrix\n",
    "\n",
    "# Example usage\n",
    "image_path = '7.png'\n",
    "matrix = list(image_to_matrix(image_path))\n",
    "ind=0\n",
    "# for m in matrix:\n",
    "#     m=m[::-1]\n",
    "#     matrix[ind]=m\n",
    "#     ind+=1\n",
    "matrix=matrix[::-1]\n",
    "# Now 'matrix' contains the pixel data as a 2D matrix\n",
    "matrix=np.array(matrix).reshape((1,-1))[0]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix\n",
    "i=0\n",
    "for element in matrix:\n",
    "    if element > 200:\n",
    "        matrix[i]=1 \n",
    "    else:\n",
    "        matrix[i]=0 \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(28):\n",
    "    print(matrix[(i)*28:(i+1)*28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8683e-03, 7.9070e-06, 9.5431e-03, 9.2309e-01, 2.5828e-04, 2.3143e-03,\n",
      "         3.5909e-06, 2.6368e-05, 4.2692e-04, 6.2461e-02]],\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data_tensor_2 = torch.tensor([matrix], dtype=torch.float32).to(device)\n",
    "pred=model(data_tensor_2)\n",
    "pred=pred.cpu()\n",
    "print(pred)\n",
    "print(np.where(pred[0]==max(pred[0]))[0][0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
